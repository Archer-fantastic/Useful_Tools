"""
TensorRT å›¾åƒåˆ†ç±»æ¨ç† Demo (ONNX -> TRT -> æ¨ç†)
æ”¯æŒåŠ¨æ€ batchã€FP16 åŠ é€Ÿã€è‡ªåŠ¨æ„å»ºå¼•æ“
"""

import os
import argparse
import time
import numpy as np
from PIL import Image
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit


# -------------------------------
# å…¨å±€é…ç½®
# -------------------------------

TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
EXPLICIT_BATCH = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)


# -------------------------------
# å›¾åƒé¢„å¤„ç†
# -------------------------------

def preprocess_image(image_path, input_size=(320, 320)):
    """é¢„å¤„ç†å›¾åƒï¼šè°ƒæ•´å¤§å°ã€å½’ä¸€åŒ–ã€è½¬ä¸º NCHW æ ¼å¼"""
    try:
        image = Image.open(image_path).convert("RGB")
        image = image.resize(input_size, Image.BILINEAR)

        # è½¬ä¸ºæ•°ç»„å¹¶å½’ä¸€åŒ–
        img_np = np.array(image).astype(np.float32) / 255.0
        img_np = (img_np - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]
        img_np = np.transpose(img_np, (2, 0, 1))  # HWC -> CHW
        img_np = np.expand_dims(img_np, axis=0)   # CHW -> NCHW

        return img_np.copy()
    except Exception as e:
        print(f"âŒ å›¾åƒé¢„å¤„ç†å¤±è´¥: {e}")
        return None


# -------------------------------
# æ„å»º TensorRT å¼•æ“
# -------------------------------

def build_engine(onnx_file, engine_file, precision="fp16", 
                 min_batch=1, opt_batch=1, max_batch=8, img_size=(320, 320)):
    """ä» ONNX æ„å»º TRT å¼•æ“"""
    if os.path.exists(engine_file):
        print(f"ğŸŸ¢ TRT å¼•æ“å·²å­˜åœ¨ï¼Œè·³è¿‡æ„å»º: {engine_file}")
        return True

    if not os.path.exists(onnx_file):
        print(f"âŒ ONNX æ–‡ä»¶ä¸å­˜åœ¨: {onnx_file}")
        return False

    print(f"ğŸ› ï¸ æ­£åœ¨æ„å»º TensorRT å¼•æ“... ({precision})")

    builder = trt.Builder(TRT_LOGGER)
    network = builder.create_network(EXPLICIT_BATCH)
    parser = trt.OnnxParser(network, TRT_LOGGER)

    with open(onnx_file, "rb") as f:
        if not parser.parse(f.read()):
            for i in range(parser.num_errors):
                print(f"è§£æé”™è¯¯: {parser.get_error(i)}")
            return False

    config = builder.create_builder_config()
    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)  # 1GB

    # åŠ¨æ€ shape è®¾ç½®
    profile = builder.create_optimization_profile()
    input_name = network.get_input(0).name
    min_shape = (min_batch, 3, img_size[1], img_size[0])
    opt_shape = (opt_batch, 3, img_size[1], img_size[0])
    max_shape = (max_batch, 3, img_size[1], img_size[0])
    profile.set_shape(input_name, min_shape=min_shape, opt_shape=opt_shape, max_shape=max_shape)
    config.add_optimization_profile(profile)

    # ç²¾åº¦è®¾ç½®
    if precision == "fp16" and builder.platform_has_fast_fp16:
        config.set_flag(trt.BuilderFlag.FP16)
        print("âœ… å·²å¯ç”¨ FP16 ç²¾åº¦")

    # åºåˆ—åŒ–å¼•æ“
    engine_bytes = builder.build_serialized_network(network, config)
    if engine_bytes is None:
        print("âŒ å¼•æ“æ„å»ºå¤±è´¥")
        return False

    with open(engine_file, "wb") as f:
        f.write(engine_bytes)
    print(f"âœ… TRT å¼•æ“å·²ä¿å­˜è‡³: {engine_file}")
    return True


# -------------------------------
# åŠ è½½å¼•æ“ & ç»‘å®šç´¢å¼•
# -------------------------------

def load_engine(engine_file):
    runtime = trt.Runtime(TRT_LOGGER)
    with open(engine_file, "rb") as f:
        engine = runtime.deserialize_cuda_engine(f.read())
    return engine


# -------------------------------
# åå¤„ç†ï¼šSoftmax + æ ‡ç­¾æ˜ å°„
# -------------------------------

def postprocess(output, labels=None):
    probs = np.exp(output) / np.sum(np.exp(output), axis=1)
    idx = np.argmax(probs, axis=1)[0]
    prob = probs[0, idx]

    cls_name = f"Class {idx}"
    if labels and idx < len(labels):
        cls_name = labels[idx]

    print("\nğŸ¯ æ¨ç†ç»“æœ:")
    print(f"  ç±»åˆ«: {cls_name} (ID={idx})")
    print(f"  ç½®ä¿¡åº¦: {prob:.4f} ({prob*100:.2f}%)")
    return {"class": cls_name, "index": int(idx), "confidence": float(prob)}


# -------------------------------
# åŠ è½½æ ‡ç­¾
# -------------------------------

def load_labels(label_file):
    if not label_file or not os.path.exists(label_file):
        return None
    with open(label_file, 'r', encoding='utf-8') as f:
        return [line.strip() for line in f if line.strip()]



# -------------------------------
# æ–°ç‰ˆæ¨ç†å‡½æ•°ï¼ˆé€‚é… TensorRT 10ï¼‰
# -------------------------------

def infer(engine, input_data):
    context = engine.create_execution_context()

    # è·å–è¾“å…¥è¾“å‡ºå¼ é‡åç§°
    input_name = engine.get_tensor_name(0)
    output_name = engine.get_tensor_name(1)

    # è®¾ç½®è¾“å…¥å½¢çŠ¶ï¼ˆåŠ¨æ€ shapeï¼‰
    context.set_input_shape(input_name, input_data.shape)

    # åˆ†é… host & device ç¼“å†²åŒº
    h_input = cuda.pagelocked_empty(trt.volume(input_data.shape), dtype=np.float32)
    h_output = cuda.pagelocked_empty(
        trt.volume(context.get_tensor_shape(output_name)), dtype=np.float32
    )
    d_input = cuda.mem_alloc(h_input.nbytes)
    d_output = cuda.mem_alloc(h_output.nbytes)

    stream = cuda.Stream()

    # æ‹·è´è¾“å…¥æ•°æ®
    np.copyto(h_input, input_data.ravel())
    cuda.memcpy_htod_async(d_input, h_input, stream)

    # è®¾ç½®å¼ é‡åœ°å€
    context.set_tensor_address(input_name, int(d_input))
    context.set_tensor_address(output_name, int(d_output))

    # æ‰§è¡Œæ¨ç†
    context.execute_async_v3(stream_handle=stream.handle)
    stream.synchronize()

    # æ‹·è´ç»“æœå› CPU
    cuda.memcpy_dtoh_async(h_output, d_output, stream)
    stream.synchronize()

    # é‡å¡‘è¾“å‡º
    output_shape = context.get_tensor_shape(output_name)
    return h_output.reshape(output_shape)


# -------------------------------
# ä¿®æ”¹ main() ä¸­æ‰“å°ä¿¡æ¯éƒ¨åˆ†
# -------------------------------

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--onnx", default=r"D:\Min\Projects\VSCodeProjects\dataset\cls_CYS250804é˜³ææ¶‚å¸ƒæœºå°¾å¤–è§‚ç‘•ç–µCCDæ£€æµ‹_æµ‹è¯•_lxm\train_res\resnet18_20251030_150116\best_model.onnx", help="è¾“å…¥ ONNX æ¨¡å‹è·¯å¾„")
    parser.add_argument("--engine", default=r"D:\Min\Projects\VSCodeProjects\dataset\cls_CYS250804é˜³ææ¶‚å¸ƒæœºå°¾å¤–è§‚ç‘•ç–µCCDæ£€æµ‹_æµ‹è¯•_lxm\train_res\resnet18_20251030_150116\defect_detection.trt", help="è¾“å‡º TRT å¼•æ“è·¯å¾„")
    parser.add_argument("--image", default=r"D:\Min\Projects\VSCodeProjects\dataset\cls_CYS250804é˜³ææ¶‚å¸ƒæœºå°¾å¤–è§‚ç‘•ç–µCCDæ£€æµ‹_æµ‹è¯•_lxm\2025102913_å¤‡ä»½\æ¼åº•æ¶‚\178_304-é¢ç§¯0.43-å®½0.18-é«˜1.4-ç¬¬5611ç‰‡--ç¬¬1æ¡-X_433.43mm-Y_7913.636ç±³-45234836è„‰å†²-07-29-22.7664ç‰¹å¾æ³•.bmp", help="è¾“å…¥æµ‹è¯•å›¾åƒè·¯å¾„")
    parser.add_argument("--labels", default=r"D:\Min\Projects\VSCodeProjects\dataset\cls_CYS250804é˜³ææ¶‚å¸ƒæœºå°¾å¤–è§‚ç‘•ç–µCCDæ£€æµ‹_æµ‹è¯•_lxm\train_res\resnet18_20251030_150116\classes.txt", help="ç±»åˆ«æ ‡ç­¾æ–‡ä»¶")
    parser.add_argument("--precision", choices=["fp32", "fp16"], default="fp16", help="ç²¾åº¦æ¨¡å¼")
    parser.add_argument("--input-size", type=int, nargs=2, default=[320, 320], help="è¾“å…¥å°ºå¯¸")
    args = parser.parse_args()

    print(f"ğŸš€ å¼€å§‹è¿è¡Œ TensorRT æ¨ç† demo (ç‰ˆæœ¬: {trt.__version__})")

    # Step 1: æ„å»ºå¼•æ“ï¼ˆæ— éœ€ä¿®æ”¹ï¼Œbuild_engine ä¸å—å½±å“ï¼‰
    if not build_engine(args.onnx, args.engine, precision=args.precision, img_size=args.input_size):
        exit(1)

    # Step 2: åŠ è½½å¼•æ“
    engine = load_engine(args.engine)

    # âœ… æ­£ç¡®è·å–è¾“å…¥/è¾“å‡ºå¼ é‡æ•°é‡å’Œåå­—ï¼ˆTRT 10 å†™æ³•ï¼‰
    num_tensors = engine.num_io_tensors  # æ–°å±æ€§
    input_name = engine.get_tensor_name(0)
    output_name = engine.get_tensor_name(1)

    print(f"ğŸ“Œ IO å¼ é‡æ€»æ•°: {num_tensors}")
    print(f"ğŸ“Œ è¾“å…¥å¼ é‡å: {input_name} (ç±»å‹: {engine.get_tensor_dtype(input_name)})")
    print(f"ğŸ“Œ è¾“å‡ºå¼ é‡å: {output_name} (ç±»å‹: {engine.get_tensor_dtype(output_name)})")

    # Step 3: é¢„å¤„ç†å›¾åƒ
    if not os.path.exists(args.image):
        print(f"âš ï¸ æµ‹è¯•å›¾åƒæœªæ‰¾åˆ°: {args.image}ï¼Œå°è¯•åˆ›å»ºä¸€å¼ éšæœºå›¾åƒ...")
        Image.fromarray(np.random.randint(0, 255, (320, 320, 3), dtype=np.uint8)).save("test.jpg")
        args.image = "test.jpg"

    input_data = preprocess_image(args.image, input_size=tuple(args.input_size))
    if input_data is None:
        print("âŒ é¢„å¤„ç†å¤±è´¥ï¼Œé€€å‡º")
        exit(1)

    # Step 4: æ¨ç†
    print("ğŸ”¥ å¼€å§‹æ¨ç†...")
    start = time.time()
    result = infer(engine, input_data)
    infer_time = (time.time() - start) * 1000
    print(f"â±ï¸ æ¨ç†è€—æ—¶: {infer_time:.2f} ms")

    # Step 5: åå¤„ç†
    labels = load_labels(args.labels)
    postprocess(result, labels)
if __name__ == "__main__":
    main()